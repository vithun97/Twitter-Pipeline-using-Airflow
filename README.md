# Twitter Data Pipeline with Airflow and Python
## Overview:

This project demonstrates how to build a Twitter data pipeline using Apache Airflow and Python. The data is extracted from Twitter, transformed using Python and Pandas, and then deployed onto an Amazon EC2 machine. The final result is stored on Amazon S3, which is an object storage service.

## Concepts Applied:

Architecture diagram of the pipeline
Installing and importing Apache Airflow
Defining the directed acyclic graph (DAG) and tasks
Execution
Setting up the Twitter API and obtaining the API key and secret key
Executing the pipeline
Deploying the code on Apache Airflow

## Technologies Used:

Python and Pandas
Apache Airflow
Amazon EC2
Amazon S3
