# Twitter Data Pipeline with Airflow and Python
## Overview:

This project demonstrates how to build a Twitter data pipeline using Apache Airflow and Python. The data is extracted from Twitter, transformed using Python and Pandas, and then deployed onto an Amazon EC2 machine. The final result is stored on Amazon S3, which is an object storage service.

## Concepts Applied:

1.Architecture diagram of the pipeline  
2.Installing and importing Apache Airflow  
3.Defining the directed acyclic graph (DAG) and tasks  
4.Execution  
5.Setting up the Twitter API and obtaining the API key and secret key  
6.Executing the pipeline  
7.Deploying the code on Apache Airflow  

## Technologies Used:

1.Python and Pandas  
2.Apache Airflow  
3.Amazon EC2  
4.Amazon S3  
